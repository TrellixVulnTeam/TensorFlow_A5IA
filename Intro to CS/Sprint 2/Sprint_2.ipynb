{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "(x_set, y_set), (x_test, y_test) = mnist.load_data()\n",
    "x_set = x_set/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Given we will not be having class next week and I cannot reasonably expect you to do work for which we will not have lectured; this weeks sprint will be broken up into two smaller pieces as was lossely voted on in class, with this being part 1.\n",
    "\n",
    "For this sprint you will be doing a process called K-Fold Cross Validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "In class you were briefly introduced to Keras, which is a high level machine learning library that can be used to create everything from an introductory model such as what you will be building to very complex models used in industry every day to handle everything from chat bots to object detection and more.\n",
    "\n",
    "### Section 1\n",
    "\n",
    "In the last sprint you did some exploration that helped you understand the dataset and what was in it, this time you are going to prepare it for training. \n",
    "\n",
    "Professor Memon had talked about in his lecture taking your data and properly holding back some of it so that later you could use it to validate if your model was working or not.\n",
    "\n",
    "For this section you will be responsible for implementing in python an algorithm called K-Fold\n",
    "\n",
    "This will be worth **40** points of the sprint\n",
    "\n",
    "\n",
    "### Section 2\n",
    "\n",
    "With K = 5 for the number of folds you will do the below:\n",
    "\n",
    "Now that you have properly segmented your data you will have to train K-1 models and validate them. The code for the model has already been implemented, you do not need to worry about that.\n",
    "\n",
    "The general procedure is:\n",
    "    1. Split your dataset into K even sets of data using the k-fold algorithm.\n",
    "    2. Train a model on set K=0\n",
    "    3. Validate the model on set K=1\n",
    "    4. Repeat for K+1 and K+2\n",
    "    \n",
    "**Note:** Training the models will take some time depending on your computer, each model will be saved so after you are sure this part is working you should only have to do it once. If you mess something up you can delete the model files and start again.\n",
    "    \n",
    "This will be worth **40** points of the sprint\n",
    "\n",
    "### Section 3\n",
    "Provide a few sentences about common pitfalls of k-fold-cross validation and training models with it.\n",
    "\n",
    "This will be worth **20** points of the sprint\n",
    "\n",
    "### Extra credit\n",
    "\n",
    "There are very many other validation methods for constructing machine learning models. Find one and implement it.\n",
    "This is worth **20** extra credit points for the sprint.\n",
    "\n",
    "\n",
    "#### Note:\n",
    "Before you begin, you can use the same virtual environments you created last week, but you must pip install h5py into them. h5py is a file format library that will be used to save the trained models. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "def k_fold_split(x_set, y_set, folds=1):\n",
    "    '''\n",
    "    Inputs: The x_set data from mnist, the y_set labels from mnist\n",
    "    Expected Output: The shuffled and K split datasets\n",
    "    '''\n",
    "    xdata = []\n",
    "    ydata = []\n",
    "     \n",
    "    new_x = list(x_set)\n",
    "    new_y = list(y_set)\n",
    "    check = len(x_set) / folds\n",
    "    fold_size = int(check)\n",
    "    for j in range(folds):\n",
    "        fold_x = []\n",
    "        fold_y = []\n",
    "        while fold_size > len(fold_x):\n",
    "            index = randrange(len(new_x))\n",
    "            fold_x.append(np.array(new_x.pop(index)).flatten()) \n",
    "            fold_y.append(new_y.pop(index))\n",
    "        xdata.append(fold_x) \n",
    "        ydata.append(fold_y) \n",
    "    return (xdata, ydata)\n",
    "x_folds, y_folds = k_fold_split(x_set, y_set, 5)\n",
    "x_folds = np.array(x_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_model():\n",
    "    mod = Sequential()\n",
    "    mod.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    mod.add(Dropout(0.2))\n",
    "    mod.add(Dense(512, activation='relu'))\n",
    "    mod.add(Dropout(0.2))\n",
    "    mod.add(Dense(10, activation='softmax'))\n",
    "    mod.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return mod\n",
    "\n",
    "\n",
    "def train_model(model, train_dataset, validation_dataset, epochs, name):\n",
    "    \n",
    "    x_set, y_set = train_dataset\n",
    "    model.fit(x_set, y_set, epochs=epochs, batch_size=128, validation_data=validation_dataset)\n",
    "    model.save(f'./{name}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hint: Neural Networks can't just handle the lables as they are, they need --categorical-- data\n",
    "#Note: You must submit the trained models along with the notebook for full credit\n",
    "def train_validate_k(x_folds, y_folds, num_folds):\n",
    "    '''\n",
    "        Inputs: x_folds, the x folds returned from the k_fold algorithm above, \n",
    "        y_folds the y folds returned from the k_fold algorithm above\n",
    "        num_folds, the number of folds used to make the x_folds and y_folds\n",
    "        Expected Output: Nothing, this function has no explicit output, \n",
    "        but there must be num_fold models trained and saved to disk\n",
    "    '''\n",
    "    \n",
    "    for j in range(num_folds):\n",
    "        \n",
    "        if j != num_folds-1:\n",
    "            res = \"Test set \" +str(i+1)+\" Validate with \" + str(i+2)\n",
    "            train_model(construct_model(), (x_folds[j], to_categorical(y_folds[j])), (x_folds[j+1], to_categorical(y_folds[j+1])),20,res)\n",
    "        else:\n",
    "            res = \"Test set \" +str(i+1)+\" Validate with \" + str(1)\n",
    "            train_model(construct_model(), (x_folds[j], to_categorical(y_folds[j])), (x_folds[0], to_categorical(y_folds[0])),20,res)   \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "12000/12000 [==============================] - 2s 157us/step - loss: 0.5032 - acc: 0.8417 - val_loss: 0.2371 - val_acc: 0.9303\n",
      "Epoch 2/20\n",
      "12000/12000 [==============================] - 1s 108us/step - loss: 0.2022 - acc: 0.9406 - val_loss: 0.1783 - val_acc: 0.9427\n",
      "Epoch 3/20\n",
      "12000/12000 [==============================] - 1s 108us/step - loss: 0.1360 - acc: 0.9569 - val_loss: 0.1280 - val_acc: 0.9593\n",
      "Epoch 4/20\n",
      "12000/12000 [==============================] - 1s 113us/step - loss: 0.0930 - acc: 0.9711 - val_loss: 0.1320 - val_acc: 0.9613\n",
      "Epoch 5/20\n",
      "12000/12000 [==============================] - 1s 109us/step - loss: 0.0692 - acc: 0.9764 - val_loss: 0.1421 - val_acc: 0.9566\n",
      "Epoch 6/20\n",
      "12000/12000 [==============================] - 1s 114us/step - loss: 0.0515 - acc: 0.9836 - val_loss: 0.1259 - val_acc: 0.9673\n",
      "Epoch 7/20\n",
      "12000/12000 [==============================] - 1s 113us/step - loss: 0.0412 - acc: 0.9861 - val_loss: 0.1644 - val_acc: 0.9570\n",
      "Epoch 8/20\n",
      "12000/12000 [==============================] - 1s 114us/step - loss: 0.0333 - acc: 0.9892 - val_loss: 0.1484 - val_acc: 0.9638\n",
      "Epoch 9/20\n",
      "12000/12000 [==============================] - 1s 114us/step - loss: 0.0273 - acc: 0.9902 - val_loss: 0.1830 - val_acc: 0.9553\n",
      "Epoch 10/20\n",
      "12000/12000 [==============================] - 1s 111us/step - loss: 0.0246 - acc: 0.9912 - val_loss: 0.1388 - val_acc: 0.9679\n",
      "Epoch 11/20\n",
      "12000/12000 [==============================] - 1s 111us/step - loss: 0.0183 - acc: 0.9936 - val_loss: 0.1522 - val_acc: 0.9663\n",
      "Epoch 12/20\n",
      "12000/12000 [==============================] - 1s 115us/step - loss: 0.0179 - acc: 0.9942 - val_loss: 0.1511 - val_acc: 0.9675\n",
      "Epoch 13/20\n",
      "12000/12000 [==============================] - 1s 116us/step - loss: 0.0163 - acc: 0.9950 - val_loss: 0.1623 - val_acc: 0.9669\n",
      "Epoch 14/20\n",
      "12000/12000 [==============================] - 1s 115us/step - loss: 0.0143 - acc: 0.9948 - val_loss: 0.1891 - val_acc: 0.9647\n",
      "Epoch 15/20\n",
      "12000/12000 [==============================] - 1s 114us/step - loss: 0.0112 - acc: 0.9967 - val_loss: 0.1629 - val_acc: 0.9677\n",
      "Epoch 16/20\n",
      "12000/12000 [==============================] - 1s 112us/step - loss: 0.0121 - acc: 0.9963 - val_loss: 0.1739 - val_acc: 0.9684\n",
      "Epoch 17/20\n",
      "12000/12000 [==============================] - 1s 118us/step - loss: 0.0086 - acc: 0.9965 - val_loss: 0.1801 - val_acc: 0.9673\n",
      "Epoch 18/20\n",
      "12000/12000 [==============================] - 1s 110us/step - loss: 0.0128 - acc: 0.9954 - val_loss: 0.1876 - val_acc: 0.9678\n",
      "Epoch 19/20\n",
      "12000/12000 [==============================] - 1s 114us/step - loss: 0.0083 - acc: 0.9971 - val_loss: 0.1686 - val_acc: 0.9692\n",
      "Epoch 20/20\n",
      "12000/12000 [==============================] - 1s 117us/step - loss: 0.0087 - acc: 0.9975 - val_loss: 0.2051 - val_acc: 0.9669\n",
      "Train on 12000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "12000/12000 [==============================] - 2s 153us/step - loss: 0.5053 - acc: 0.8401 - val_loss: 0.2695 - val_acc: 0.9199\n",
      "Epoch 2/20\n",
      "12000/12000 [==============================] - 1s 108us/step - loss: 0.2041 - acc: 0.9371 - val_loss: 0.1824 - val_acc: 0.9450\n",
      "Epoch 3/20\n",
      "12000/12000 [==============================] - 1s 113us/step - loss: 0.1371 - acc: 0.9568 - val_loss: 0.1722 - val_acc: 0.9477\n",
      "Epoch 4/20\n",
      "12000/12000 [==============================] - 1s 121us/step - loss: 0.0927 - acc: 0.9695 - val_loss: 0.1599 - val_acc: 0.9529\n",
      "Epoch 5/20\n",
      "12000/12000 [==============================] - 1s 113us/step - loss: 0.0700 - acc: 0.9781 - val_loss: 0.1625 - val_acc: 0.9543\n",
      "Epoch 6/20\n",
      "12000/12000 [==============================] - 1s 109us/step - loss: 0.0513 - acc: 0.9832 - val_loss: 0.1531 - val_acc: 0.9581\n",
      "Epoch 7/20\n",
      "12000/12000 [==============================] - 1s 120us/step - loss: 0.0476 - acc: 0.9847 - val_loss: 0.1627 - val_acc: 0.9578\n",
      "Epoch 8/20\n",
      "12000/12000 [==============================] - 1s 112us/step - loss: 0.0330 - acc: 0.9893 - val_loss: 0.1544 - val_acc: 0.9641\n",
      "Epoch 9/20\n",
      "12000/12000 [==============================] - 1s 115us/step - loss: 0.0243 - acc: 0.9917 - val_loss: 0.1840 - val_acc: 0.9602\n",
      "Epoch 10/20\n",
      "12000/12000 [==============================] - 1s 118us/step - loss: 0.0241 - acc: 0.9928 - val_loss: 0.1956 - val_acc: 0.9564\n",
      "Epoch 11/20\n",
      "12000/12000 [==============================] - 1s 111us/step - loss: 0.0174 - acc: 0.9934 - val_loss: 0.2018 - val_acc: 0.9591\n",
      "Epoch 12/20\n",
      "12000/12000 [==============================] - 1s 109us/step - loss: 0.0158 - acc: 0.9944 - val_loss: 0.1869 - val_acc: 0.9634\n",
      "Epoch 13/20\n",
      "12000/12000 [==============================] - 1s 118us/step - loss: 0.0167 - acc: 0.9943 - val_loss: 0.1926 - val_acc: 0.9625\n",
      "Epoch 14/20\n",
      "12000/12000 [==============================] - 1s 112us/step - loss: 0.0129 - acc: 0.9957 - val_loss: 0.2208 - val_acc: 0.9606\n",
      "Epoch 15/20\n",
      "12000/12000 [==============================] - 1s 113us/step - loss: 0.0173 - acc: 0.9952 - val_loss: 0.1925 - val_acc: 0.9660\n",
      "Epoch 16/20\n",
      "12000/12000 [==============================] - 1s 116us/step - loss: 0.0112 - acc: 0.9958 - val_loss: 0.2086 - val_acc: 0.9631\n",
      "Epoch 17/20\n",
      "12000/12000 [==============================] - 1s 116us/step - loss: 0.0102 - acc: 0.9965 - val_loss: 0.2247 - val_acc: 0.9630\n",
      "Epoch 18/20\n",
      "12000/12000 [==============================] - 1s 111us/step - loss: 0.0139 - acc: 0.9959 - val_loss: 0.2296 - val_acc: 0.9636\n",
      "Epoch 19/20\n",
      "12000/12000 [==============================] - 1s 112us/step - loss: 0.0086 - acc: 0.9968 - val_loss: 0.2140 - val_acc: 0.9651\n",
      "Epoch 20/20\n",
      "12000/12000 [==============================] - 1s 109us/step - loss: 0.0101 - acc: 0.9964 - val_loss: 0.2126 - val_acc: 0.9667\n",
      "Train on 12000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "12000/12000 [==============================] - 2s 140us/step - loss: 0.5168 - acc: 0.8404 - val_loss: 0.3423 - val_acc: 0.8915\n",
      "Epoch 2/20\n",
      "12000/12000 [==============================] - 1s 111us/step - loss: 0.2240 - acc: 0.9328 - val_loss: 0.2546 - val_acc: 0.9200\n",
      "Epoch 3/20\n",
      "12000/12000 [==============================] - 1s 108us/step - loss: 0.1508 - acc: 0.9536 - val_loss: 0.1675 - val_acc: 0.9503\n",
      "Epoch 4/20\n",
      "12000/12000 [==============================] - 1s 109us/step - loss: 0.1056 - acc: 0.9646 - val_loss: 0.1632 - val_acc: 0.9522\n",
      "Epoch 5/20\n",
      "12000/12000 [==============================] - 1s 110us/step - loss: 0.0807 - acc: 0.9726 - val_loss: 0.1626 - val_acc: 0.9548\n",
      "Epoch 6/20\n",
      "12000/12000 [==============================] - 1s 114us/step - loss: 0.0561 - acc: 0.9801 - val_loss: 0.1523 - val_acc: 0.9577\n",
      "Epoch 7/20\n",
      "12000/12000 [==============================] - 1s 114us/step - loss: 0.0483 - acc: 0.9845 - val_loss: 0.1516 - val_acc: 0.9600\n",
      "Epoch 8/20\n",
      "12000/12000 [==============================] - 1s 110us/step - loss: 0.0377 - acc: 0.9872 - val_loss: 0.1452 - val_acc: 0.9648\n",
      "Epoch 9/20\n",
      "12000/12000 [==============================] - 1s 108us/step - loss: 0.0325 - acc: 0.9892 - val_loss: 0.1539 - val_acc: 0.9638\n",
      "Epoch 10/20\n",
      "12000/12000 [==============================] - 1s 110us/step - loss: 0.0248 - acc: 0.9919 - val_loss: 0.2006 - val_acc: 0.9557\n",
      "Epoch 11/20\n",
      "12000/12000 [==============================] - 1s 111us/step - loss: 0.0212 - acc: 0.9928 - val_loss: 0.1878 - val_acc: 0.9614\n",
      "Epoch 12/20\n",
      "12000/12000 [==============================] - 1s 105us/step - loss: 0.0203 - acc: 0.9933 - val_loss: 0.2171 - val_acc: 0.9561\n",
      "Epoch 13/20\n",
      "12000/12000 [==============================] - 1s 104us/step - loss: 0.0183 - acc: 0.9940 - val_loss: 0.1820 - val_acc: 0.9628\n",
      "Epoch 14/20\n",
      "12000/12000 [==============================] - 1s 110us/step - loss: 0.0127 - acc: 0.9958 - val_loss: 0.1944 - val_acc: 0.9638\n",
      "Epoch 15/20\n",
      "12000/12000 [==============================] - 1s 108us/step - loss: 0.0127 - acc: 0.9958 - val_loss: 0.2126 - val_acc: 0.9613\n",
      "Epoch 16/20\n",
      "12000/12000 [==============================] - 1s 106us/step - loss: 0.0135 - acc: 0.9944 - val_loss: 0.1946 - val_acc: 0.9665\n",
      "Epoch 17/20\n",
      "12000/12000 [==============================] - 1s 111us/step - loss: 0.0125 - acc: 0.9963 - val_loss: 0.2068 - val_acc: 0.9617\n",
      "Epoch 18/20\n",
      "12000/12000 [==============================] - 1s 107us/step - loss: 0.0071 - acc: 0.9978 - val_loss: 0.2289 - val_acc: 0.9607\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000/12000 [==============================] - 1s 107us/step - loss: 0.0107 - acc: 0.9962 - val_loss: 0.2359 - val_acc: 0.9594\n",
      "Epoch 20/20\n",
      "12000/12000 [==============================] - 1s 111us/step - loss: 0.0111 - acc: 0.9962 - val_loss: 0.2210 - val_acc: 0.9627\n",
      "Train on 12000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "12000/12000 [==============================] - 2s 160us/step - loss: 0.5250 - acc: 0.8350 - val_loss: 0.2445 - val_acc: 0.9230\n",
      "Epoch 2/20\n",
      "12000/12000 [==============================] - 1s 113us/step - loss: 0.2198 - acc: 0.9323 - val_loss: 0.1977 - val_acc: 0.9431\n",
      "Epoch 3/20\n",
      "12000/12000 [==============================] - 1s 116us/step - loss: 0.1433 - acc: 0.9576 - val_loss: 0.1752 - val_acc: 0.9447\n",
      "Epoch 4/20\n",
      "12000/12000 [==============================] - 1s 115us/step - loss: 0.1005 - acc: 0.9675 - val_loss: 0.1434 - val_acc: 0.9573\n",
      "Epoch 5/20\n",
      "12000/12000 [==============================] - 1s 113us/step - loss: 0.0713 - acc: 0.9761 - val_loss: 0.1859 - val_acc: 0.9486\n",
      "Epoch 6/20\n",
      "12000/12000 [==============================] - 1s 109us/step - loss: 0.0540 - acc: 0.9817 - val_loss: 0.1613 - val_acc: 0.9569\n",
      "Epoch 7/20\n",
      "12000/12000 [==============================] - 1s 113us/step - loss: 0.0444 - acc: 0.9848 - val_loss: 0.1622 - val_acc: 0.9585\n",
      "Epoch 8/20\n",
      "12000/12000 [==============================] - 1s 117us/step - loss: 0.0355 - acc: 0.9887 - val_loss: 0.1506 - val_acc: 0.9636\n",
      "Epoch 9/20\n",
      "12000/12000 [==============================] - 1s 117us/step - loss: 0.0276 - acc: 0.9904 - val_loss: 0.1718 - val_acc: 0.9603\n",
      "Epoch 10/20\n",
      "12000/12000 [==============================] - 1s 115us/step - loss: 0.0215 - acc: 0.9928 - val_loss: 0.1651 - val_acc: 0.9640\n",
      "Epoch 11/20\n",
      "12000/12000 [==============================] - 1s 115us/step - loss: 0.0218 - acc: 0.9927 - val_loss: 0.2058 - val_acc: 0.9592\n",
      "Epoch 12/20\n",
      "12000/12000 [==============================] - 1s 116us/step - loss: 0.0166 - acc: 0.9948 - val_loss: 0.1717 - val_acc: 0.9645\n",
      "Epoch 13/20\n",
      "12000/12000 [==============================] - 1s 111us/step - loss: 0.0184 - acc: 0.9938 - val_loss: 0.2021 - val_acc: 0.9613\n",
      "Epoch 14/20\n",
      "12000/12000 [==============================] - 1s 112us/step - loss: 0.0134 - acc: 0.9954 - val_loss: 0.2029 - val_acc: 0.9632\n",
      "Epoch 15/20\n",
      "12000/12000 [==============================] - 1s 109us/step - loss: 0.0115 - acc: 0.9958 - val_loss: 0.2276 - val_acc: 0.9615\n",
      "Epoch 16/20\n",
      "12000/12000 [==============================] - 1s 107us/step - loss: 0.0133 - acc: 0.9960 - val_loss: 0.2098 - val_acc: 0.9612\n",
      "Epoch 17/20\n",
      "12000/12000 [==============================] - 1s 109us/step - loss: 0.0105 - acc: 0.9966 - val_loss: 0.2464 - val_acc: 0.9580\n",
      "Epoch 18/20\n",
      "12000/12000 [==============================] - 1s 114us/step - loss: 0.0109 - acc: 0.9962 - val_loss: 0.2248 - val_acc: 0.9627\n",
      "Epoch 19/20\n",
      "12000/12000 [==============================] - 1s 116us/step - loss: 0.0067 - acc: 0.9968 - val_loss: 0.2467 - val_acc: 0.9617\n",
      "Epoch 20/20\n",
      "12000/12000 [==============================] - 1s 112us/step - loss: 0.0116 - acc: 0.9965 - val_loss: 0.2413 - val_acc: 0.9637\n",
      "Train on 12000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "12000/12000 [==============================] - 2s 158us/step - loss: 0.5340 - acc: 0.8348 - val_loss: 0.2680 - val_acc: 0.9186\n",
      "Epoch 2/20\n",
      "12000/12000 [==============================] - 1s 109us/step - loss: 0.2168 - acc: 0.9320 - val_loss: 0.2211 - val_acc: 0.9315\n",
      "Epoch 3/20\n",
      "12000/12000 [==============================] - 1s 110us/step - loss: 0.1420 - acc: 0.9567 - val_loss: 0.1965 - val_acc: 0.9400\n",
      "Epoch 4/20\n",
      "12000/12000 [==============================] - 1s 108us/step - loss: 0.1027 - acc: 0.9690 - val_loss: 0.1530 - val_acc: 0.9574\n",
      "Epoch 5/20\n",
      "12000/12000 [==============================] - 1s 109us/step - loss: 0.0775 - acc: 0.9743 - val_loss: 0.1333 - val_acc: 0.9613\n",
      "Epoch 6/20\n",
      "12000/12000 [==============================] - 1s 112us/step - loss: 0.0580 - acc: 0.9814 - val_loss: 0.1403 - val_acc: 0.9630\n",
      "Epoch 7/20\n",
      "12000/12000 [==============================] - 1s 111us/step - loss: 0.0447 - acc: 0.9864 - val_loss: 0.1537 - val_acc: 0.9609\n",
      "Epoch 8/20\n",
      "12000/12000 [==============================] - 1s 105us/step - loss: 0.0353 - acc: 0.9876 - val_loss: 0.1649 - val_acc: 0.9604\n",
      "Epoch 9/20\n",
      "12000/12000 [==============================] - 1s 108us/step - loss: 0.0309 - acc: 0.9898 - val_loss: 0.1492 - val_acc: 0.9653\n",
      "Epoch 10/20\n",
      "12000/12000 [==============================] - 1s 109us/step - loss: 0.0240 - acc: 0.9918 - val_loss: 0.1443 - val_acc: 0.9671\n",
      "Epoch 11/20\n",
      "12000/12000 [==============================] - 1s 115us/step - loss: 0.0219 - acc: 0.9926 - val_loss: 0.1496 - val_acc: 0.9663\n",
      "Epoch 12/20\n",
      "12000/12000 [==============================] - 1s 110us/step - loss: 0.0183 - acc: 0.9938 - val_loss: 0.1535 - val_acc: 0.9695\n",
      "Epoch 13/20\n",
      "12000/12000 [==============================] - 1s 109us/step - loss: 0.0140 - acc: 0.9952 - val_loss: 0.1891 - val_acc: 0.9633\n",
      "Epoch 14/20\n",
      "12000/12000 [==============================] - 1s 108us/step - loss: 0.0124 - acc: 0.9962 - val_loss: 0.1766 - val_acc: 0.9674\n",
      "Epoch 15/20\n",
      "12000/12000 [==============================] - 1s 110us/step - loss: 0.0146 - acc: 0.9951 - val_loss: 0.1848 - val_acc: 0.9656\n",
      "Epoch 16/20\n",
      "12000/12000 [==============================] - 1s 105us/step - loss: 0.0096 - acc: 0.9967 - val_loss: 0.1898 - val_acc: 0.9683\n",
      "Epoch 17/20\n",
      "12000/12000 [==============================] - 1s 106us/step - loss: 0.0117 - acc: 0.9967 - val_loss: 0.1921 - val_acc: 0.9672\n",
      "Epoch 18/20\n",
      "12000/12000 [==============================] - 1s 107us/step - loss: 0.0104 - acc: 0.9967 - val_loss: 0.1951 - val_acc: 0.9684\n",
      "Epoch 19/20\n",
      "12000/12000 [==============================] - 1s 111us/step - loss: 0.0076 - acc: 0.9976 - val_loss: 0.2024 - val_acc: 0.9670\n",
      "Epoch 20/20\n",
      "12000/12000 [==============================] - 2s 132us/step - loss: 0.0086 - acc: 0.9971 - val_loss: 0.2310 - val_acc: 0.9652\n"
     ]
    }
   ],
   "source": [
    "train_validate_k(x_folds, y_folds, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 3, write a few sentences below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Leakage\n",
    "\n",
    "If there is information coming outside from different sources CV wouldn't work well for this sort of use case. \n",
    "\n",
    "### High Imbalances\n",
    "\n",
    "If the data is highly imbalanced then CV wouldn't work well for this use case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
